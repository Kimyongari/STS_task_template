{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b169ffae-5436-4d0a-b8ab-c4c1130882e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('/Users/kim-yongjun/Documents/부스트캠프 AI Tech 7기/5.5. NLP 기초 프로젝트/nlp_project/train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987b259-9929-4fcc-8af0-84dbade164b5",
   "metadata": {},
   "source": [
    "### 1. Label의 균형을 맞춰야 함. \n",
    "(Augumentation을 통해 해결)\n",
    "### 2. 자주 등장하는 'PERSON' 단어를 Tokenizer마다 다르게 해석할 수 있으므로 하나의 Special Token으로 추가해야 함.\n",
    "(Modeling 단계에서 추가)\n",
    "### 3. 같은 단어들이 반복되는 문장들을 교정해야 함.\n",
    "(Preprocessing 단계에서 해결)\n",
    "### 4. 대문자들을 전부 소문자로 바꿔 혼란을 줄여야 함.\n",
    "(Preprocessing 단계에서 해결), 추가적으로 '!', '?', '.'을 제외한 특수문자는 삭제하도록 하였음.\n",
    "### 5. 띄어쓰기 교정을 통해 올바른 문장으로 바꿔야 함.\n",
    "(Preprocessing 단계에서 해결)\n",
    "### 6. 오타로 인한 [UNK] Token 생성을 줄여야 함.\n",
    "(Preprocessing 단계에서 해결)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69168db3-cf57-42c7-9a4d-ed1f771b2d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "야호야호야호 냥 냥 냥 냥 냥 ㅎㅎㅎㅎ !!!!!!! ㅋㅋㅋㅋㅋ\n",
      "야호야호야호 냥 냥 냥 냥 냥 ㅎㅎ !! ㅋㅋ\n",
      "야호야호야호 냥 냥 ㅎㅎ !! ㅋㅋ\n",
      "야호야호 냥 냥 ㅎㅎ !! ㅋㅋ\n"
     ]
    }
   ],
   "source": [
    "def reduce_repeated_chr(sentence):\n",
    "    # 정규식 패턴: 같은 문자가 3번 이상 반복되는 경우 찾기\n",
    "    pattern = r'(.)\\1{2,}'\n",
    "    return re.sub(pattern, r'\\1\\1', sentence)\n",
    "\n",
    "def reduce_repeated_words(sentence):\n",
    "    # 정규식 패턴: 같은 단어가 3번 이상 반복되는 경우 찾기 (띄워쓰기 포함)\n",
    "    pattern = r'\\b(\\w+)\\b(?:\\s+\\1){2,}'\n",
    "    return re.sub(pattern, r'\\1 \\1', sentence)\n",
    "    \n",
    "def reduce_repeated_phrases(sentence):\n",
    "    # 정규식 패턴: 같은 단어나 구절이 3번 이상 반복되는 경우 찾기\n",
    "    pattern = r'(\\w+)\\1{2,}'\n",
    "    return re.sub(pattern, r'\\1\\1', sentence)\n",
    "\n",
    "sentence = '야호야호야호 냥 냥 냥 냥 냥 ㅎㅎㅎㅎ !!!!!!! ㅋㅋㅋㅋㅋ'\n",
    "print(sentence)\n",
    "sentence = reduce_repeated_chr(sentence)\n",
    "print(sentence)\n",
    "sentence = reduce_repeated_words(sentence)\n",
    "print(sentence)\n",
    "sentence = reduce_repeated_phrases(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a2d2b6-9c65-4a05-b3f9-824ff1a9ef91",
   "metadata": {},
   "source": [
    "## !!!!!!! 같이 반복되는 단어들을 2자로 줄입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c42e5a20-3188-413a-8e31-a53d410091f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erase_special_chr(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    pattern = r'[^ㄱ-ㅎ가-힣a-zA-Z0-9\\s?.!]'\n",
    "    sentence = re.sub(pattern, '', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8297bc6-3448-41cd-b63b-1ea6ba8a88a0",
   "metadata": {},
   "source": [
    "## 문장의 영문들을 소문자로 바꾸고 '!', '.', '?'를 제외한 특수문자를 전부 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a51b7496-c07e-4085-8c99-d7a666a34f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "책을많이읽어봣는데도맞춘법에약해요 ㅋㅋㅋㅋㅋ.\n",
      "책을 많이 읽어봤는데도 맞춤법에 약해요 ㅋㅋㅋㅋㅋ.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "class SpellChecker:\n",
    "    def __init__(self):\n",
    "        # 직접 찾아서 넣은 passportKey와 base_url\n",
    "        self.base_url = 'https://m.search.naver.com/p/csearch/ocontent/util/SpellerProxy'\n",
    "        self.passport_key = '062220e9b6aee9cf862e0ca85fb511078b8f04d0'  # 직접 찾은 passportKey 입력\n",
    "\n",
    "    def spell_check(self, text):\n",
    "        # base_url이나 passport_key가 없는 경우 에러 반환\n",
    "        if self.passport_key is None or self.base_url is None:\n",
    "            return \"Error: Missing base_url or passport_key\"\n",
    "        \n",
    "        payload = {\n",
    "            'passportKey': self.passport_key,\n",
    "            'where': 'nexearch',\n",
    "            'color_blindness': 0,\n",
    "            'q': text\n",
    "        }\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, Gecko) Chrome/129.0.0.0 Safari/537.36',\n",
    "            'Referer': 'https://search.naver.com/',\n",
    "        }\n",
    "        result_response = requests.get(self.base_url, headers=headers, params=payload)\n",
    "        return json.loads(result_response.text)['message']['result']['notag_html']\n",
    "\n",
    "# Usage\n",
    "checker = SpellChecker()\n",
    "sentence = '책을많이읽어봣는데도맞춘법에약해요 ㅋㅋㅋㅋㅋ.'\n",
    "print(sentence)\n",
    "result = checker.spell_check(sentence)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d194-d5ca-4173-8f9c-691d1a0c1105",
   "metadata": {},
   "source": [
    "## 맞춤법 교정 라이브러리를 통해 오타와 띄워쓰기를 교정합니다.\n",
    "## 네이버 맞춤법 검사기를 통해 교정된 문장을 가져옵니다.\n",
    "## 네이버에 맞춤법 검사기를 검색 후 소스보기에서 ctrl+f , passport를 검색하여 키를 붙여넣습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80217f2e-6bee-4aa6-99dd-5645a09cf487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE : ~우물안개구리바다의넓음은 몰라도 하늘에 푸르름은 안다 !!!!!!~ 몬가 멋진 말이죠????? ㅋㅋㅋㅋㅋ\n",
      "SENTENCE : ~우물안개구리바다의넓음은 몰라도 하늘에 푸르름은 안다 !!~ 몬가 멋진 말이죠?? ㅋㅋ\n",
      "sentence  우물 안 개구리 바다의 넓음은 몰라도 하늘에 푸르름은 안다!! 뭔가 멋진 말이죠?? ㅋㅋ\n"
     ]
    }
   ],
   "source": [
    "sentence = 'SENTENCE : ~우물안개구리바다의넓음은 몰라도 하늘에 푸르름은 안다 !!!!!!~ 몬가 멋진 말이죠????? ㅋㅋㅋㅋㅋ'\n",
    "print(sentence)\n",
    "sentence = reduce_repeated_chr(sentence)\n",
    "sentence = reduce_repeated_words(sentence)\n",
    "sentence = reduce_repeated_phrases(sentence)\n",
    "print(sentence)\n",
    "sentence = erase_special_chr(sentence)\n",
    "sentence = checker.spell_check(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aee2d3bb-9ac0-4137-8311-06fc248b84d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    sentence = reduce_repeated_chr(sentence)\n",
    "    sentence = reduce_repeated_words(sentence)\n",
    "    sentence = reduce_repeated_phrases(sentence)\n",
    "    sentence = erase_special_chr(sentence)\n",
    "    sentence = checker.spell_check(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c636c4dc-e2c1-4de0-904a-a97214c280d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 9324/9324 [10:46<00:00, 14.42it/s]\n",
      "100%|███████████████████████████████████████| 9324/9324 [10:43<00:00, 14.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df['sentence_1'] = df['sentence_1'].progress_map(preprocessing)\n",
    "df['sentence_2'] = df['sentence_2'].progress_map(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9722494-c563-4dd6-a308-2e440ceed516",
   "metadata": {},
   "source": [
    "## 선언한 함수들을 통합한 preprocessing을 통해 데이터들을 전처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c899522-f88f-4ec3-a8ef-c98dd0797cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3113                 삶에 대해 다시 한번 생각해 볼 수 있는 좋은 시간이었습니다\n",
       "2093                         별 내용은 없고 여주 몸매는 좋으나 그게 다임\n",
       "722                                     반려동물 처벌 높여주세요.\n",
       "5538                                  person 님 정말 팬이에요\n",
       "4352                            사건이 해결되지 않은 몰카 피해자입니다.\n",
       "2226                              남은 시간 행복하게 보내고 오세요!!\n",
       "5780                                       우리도 곧 업 업!!\n",
       "6275    이재명 전시장 지지자의 악의적 sns 활동의 당과 청와대의 진상 규명을 요구합니다.\n",
       "6109                                    천안함 재조사 요구합니다!\n",
       "735                                        사법고시를 폐지하세요\n",
       "603       작년 여름 에어컨을 6월에 주문했는데 8월 말에 설치했어요 얼른 설치하세요 ㅋㅋ\n",
       "1827                       국회의원 임금을 최저 임금으로 지급하는 청원입니다\n",
       "2298                                       박철수 감독의 유작.\n",
       "872                                     조여옥 대위 처벌해 주세요\n",
       "5071                                  엘처럼 멋지게 나도 살 겁니다\n",
       "559                         다음에 태도가 작품이 될 때 리뷰도 올려주세요!\n",
       "435                                      오오 이쁘네요 여기 ㅎㅎ\n",
       "4649                                       계속 볼 겁니다 흐흐\n",
       "4186                          ㅎㅎ 지금 소타로 얼마나 나올지 궁금하네요.\n",
       "4059                                       가 빨리 개봉하길..\n",
       "Name: sentence_1, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence_1'].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af28a924-0bed-4f98-baf2-02c01fbdc88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661                  멋진 기세.. 그리고 산드라 블록.. 술과 사랑..\n",
       "8334                  사진같이 크게 도약하는 한 해가 되시길 바랍니다.\n",
       "7769                     장난 청원하는 사람들 엄격히 처벌해 주세요.\n",
       "6129                          남자 강제 군대 징병은 위헌입니다.\n",
       "2415                                   와 너무 귀여워요 \n",
       "4172                             청소년 보호법 폐지해 주세요!\n",
       "4423             차량 구입 시 실사 용주가 차량을 구매하도록 조치 바랍니다\n",
       "6755       남북 과제의 최우선 항목 중 역사공동조사 부분을 꼭 포함하여 주세요.\n",
       "1983                      중국발 미세먼지 중국에 꼭 항의해야 합니다\n",
       "6545                            누구를 위한 대체공휴일인가요? \n",
       "84                                   천천히 회복하면서 휴식\n",
       "8721                                  자연이 역시 최고네요\n",
       "5708                             과연 믿고 보는 기타노 다케시\n",
       "6601                                  애들이 많이 불쌍..\n",
       "2660           sns를 많이 사용하시는 분들에게 좋은 콘텐츠인 것 같습니다.\n",
       "6676    아파트에서 자동차가 자유롭게 다닐 수 있는 일반 도로를 건설하고 있습니다.\n",
       "2551                                근데 연재는 완료되었는데\n",
       "3539                          그래도 이루어졌으면 더 좋았을걸..\n",
       "7020                     일을 하지 않으려면 세금을 적당히 걷습니다.\n",
       "7170                              야근 방지 실현화 시켜주세요\n",
       "Name: sentence_2, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence_2'].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a305d0-8cc2-47da-a9b6-92d4bd6c8ee7",
   "metadata": {},
   "source": [
    "## 전처리 후의 데이터는 띄워쓰기나 중복, 오타가 많이 사라진 모습을 보인다.\n",
    "## 하지만 고유 명사는 맞춤법 교정을 통한 교정이 어려워 보인다. ex) mb > 명박 , 이제명 > 이재명 등\n",
    "## 모델의 성능을 위해서는 몇몇의 label 이상이 있거나 교정이 어려운 행을 삭제하는 것이 도움이 됨을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6035006d-00d6-4712-aaa1-50f4d1064af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
